=== JDBC integrations
General principles to use each JDBC integration:

* Bucket4j authors do not provide create a table for store buckets, you must make the table personally.
Examples of DDL provided for each integration.
* You should create a trigger or a scheduler that will clear your bucket storage table since DBMS is not IMDB, and DBMS don't give TTL the opportunity.

==== Overriding table and columns naming scheme
.There is three naming parameters
* `tableName` - name of table to use as a Buckets store. Default value is `bucket`
* `idName` - name of primary key column. Default value is `id`
* `stateName` - name of column to store state of bucket. Default value is `state`

You can change naming as you wish, at proxy-manager build time. Bellow is example for Mysql,
the code for other integrations will be the same

[source, java]
----
MySQLSelectForUpdateBasedProxyManager<Long> proxyManager = Bucket4jMySQL
    .selectForUpdateBasedBuilder(dataSource)
    .table("user_buckets")
    .idColumn("user_id")
    .stateColumn("state_bytes")
    .build()
----

==== Overriding type of primary key
By default `java.lang.Long` is used as Java representation of value for primary-key column,
and it is expected that type of primary column must be assigned from Long during specifying parameters of `PreparedStatement`. +

Sometimes you want to have to setting up something else for primary key column, for example `java.lang.String` and its correspondent type in database.
You can configure custom primary-key type at proxy-manager build time. Bellow is example for PostgreSQL,
the code for other integrations will be the same
[source,sql]
----
CREATE TABLE IF NOT EXISTS bucket(id VARCHAR PRIMARY KEY, state BYTEA);
----
[source, java]
----
PostgreSQLSelectForUpdateBasedProxyManager<String> proxyManager = Bucket4jPostgreSQL
    .selectForUpdateBasedBuilder(dataSource)
    .primaryKeyMapper(PrimaryKeyMapper.STRING)
    .build();
----
There are several predefined mappers defined inside `io.github.bucket4j.distributed.jdbc.PrimaryKeyMapper`,
if nothing suitable then you can define own by implementing this interface.

==== Expiration Policy
Relational databases have no built-in auto-expiration functionality like for example Redis has.
For all Jdbc integrations Bucket4j just calculates `expires_at` column if expire-policy is configured.
Then, you need to manually trigger the removing of expired bucket, like bellow
[source,sql]
----
CREATE TABLE IF NOT EXISTS bucket(id BIGINT PRIMARY KEY, state BYTEA, expires_at BIGINT);
----
[source, java]
----
PostgreSQLSelectForUpdateBasedProxyManager<Long> proxyManager = Bucket4jPostgreSQL
    .selectForUpdateBasedBuilder(dataSource)
    .expirationAfterWrite(basedOnTimeForRefillingBucketUpToMax(Duration.ofSeconds(60)))
    .build();

private static final int MAX_TO_REMOVE_IN_ONE_TRANSACTION = 1_000;
private static final int THRESHOLD_TO_CONTINUE_REMOVING = 50;

// once per day at 4:30 morning
@Scheduled(cron = "0 30 4 * * *")
public void scheduleFixedDelayTask() {
    int removedKeysCount;
    do {
        removedCount = proxyManager.removeExpired(MAX_TO_REMOVE_IN_ONE_TRANSACTION);
        if (removedKeysCount > 0) {
            logger.info("Removed {} expired buckets", removedCount);
        } else {
            logger.info("There are no expired buckets to remove");
        }
   } while (removedCount > THRESHOLD_TO_CONTINUE_REMOVING)
}
----

include::postgresql.adoc[]

include::mysql.adoc[]

include::mariadb.adoc[]

include::oracle.adoc[]

include::mssql.adoc[]

include::db2.adoc[]

